# 転移可能性が生じる要因についての考察
敵対的摂動が**生成元とは異なるモデルに対しても有効性を発揮**しうるのは良く知られている事実であり，これは攻撃者にとって極めて都合がよい．敵対的摂動は特定のモデルに依存した形で生成される（勾配情報を活用するFGSMや損失関数を利用するUAPなど）ことを踏まえると，他のモデルに対しても転用可能であるという性質が生じる．  
ここでは，転移可能性を説明しうる方法として以下の二つ述べる．
- 入力空間の幾何的分割の視点に基づく考察
- 汎関数的視点による考察   

いずれも，既存の文献と重複する内容が存在すると思われるが，後者に関しては**筆者独自の解釈**が多分に含まれているため，その真偽や妥当性には充分注意されたし．

## 入力空間の幾何的分割の視点に基づく考察
ここでは，敵対的摂動を入力空間$\mathcal{X}$での座標への一様作用と解釈することで，敵対摂動が転移性をもつ理由について考察を行う．  
分類タスクは$f:\mathcal{X} \to \boldsymbol{y}$の写像として解釈することができる．
- $\mathcal{X}$：入力空間
- $\boldsymbol{y}$：確率分布ベクトル  

そのため，深層学習モデルはモデルのパラメータ空間内で表現可能な関数の範囲で上記の関数$f$を訓練過程で近似することになる．そのため，モデルのアーキテクチャは異なることで表現可能な関数の範囲が異なるが，本質的には同じ関数の近似を試みている．  

ここで十分良く訓練された異なるアーキテクチャのモデル$f_1,f_2$を考える．  
この時，入力空間$\mathcal{X}$は各モデルによってどのラベル$\hat{y}$が付けられるかによって，いくつかの部分空間に分割することができる．ここで実際の正解ラベルが変わる境界とモデルの判断基準となる入力空間の境界に差異がある部分に誤差が生じ，その領域に相当する入力が与えられた時，モデルは分類を誤るのである．  
敵対的摂動は入力をこれらの誤分類領域へと誘導するための作用として解釈することができる．実際にUAPでは，訓練データを最も効率よく誤分類領域へと送ることができるような摂動テンソルが学習される．  

さて，ここで重要なのは **「異なるモデル間でどれほど入力空間での分類境界が異なるか？」** という点である．実際の入力空間は非常に高次元であるため，モデルごとの分類境界を可視化することは難しいが，各ラベルに対応する入力空間は**モデル間で大部分が一致している**と考えるのが妥当である．    
なぜなら，モデルごとに入力空間の分割が大きく異なる場合，一方のモデルの分類精度が著しく悪いことが想定されるためである．  
そのため，各ラベルに対応する入力空間は異なるラベル間で大部分を共有していると考えるのは妥当である．では，このような条件下でどのような時に高い転移可能性を示すのだろうか．この答えの一つとしては，転移対象モデルの分類境界が，どれだけ転移元のモデルと類似性を持つかという点が挙げられる．  
モデルがどの入力に対して誤分類を行うかはモデルによって異なるが，敵対的摂動は特定のモデルを騙すことに特化して訓練される．すなわち，敵対的摂動は訓練モデルの分類境界を容易に超える方向への摂動となる．そのため，誤分類の傾向が似ているモデルについては同様の敵対的摂動が有効性を発揮する一方で，そうでないモデルに関しては転移性は限定的となると考えらえる．

以上から，敵対的摂動の転移可能性は，入力空間の幾何的分割構造がモデル間で類似しているという仮定の元に説明される．  

## 汎関数的視点での転移可能性に関する考察
本節では，深層学習モデルの訓練過程を汎函数の最小値探索問題として定義することで，汎函数としての視点から敵対的摂動が持つ転移可能性の原因について考察し，またモデル構造の依存性を抑えた転移可能性の高い敵対的摂動の生成手法について考察する．  
なお，本節は**深層学習の訓練過程に対する筆者独自の解釈**を多分に含み，妥当性や正当性に幾許かの疑念がある点を念頭に置かれたい．

### 深層学習の訓練過程の汎函数最小化問題としての再定義
深層学習が近似することを目指すタスクに対応する真の関数を$f^*$とする．$f^*$は回帰タスクであったり分類タスクであったり，はたまた生成タスクであったりと，多様なタスクに対応しうるが何らかの関数として見なすことができる処理に対応し，関数がどのようなものであるかは深層学習モデルが近似するタスクによってまちまちである．  

深層学習の訓練過程は，理想的には以下の問題として定式化することができる．
$$
    f^* = \argmin\mathcal{L}(f) = \argmin\mathbb{E}_{x\in \mathcal{X}}[Loss(f(x),y)]
$$
これは入力空間全域にわたる損失関数の和を最小化する関数の探索問題，すなわち汎函数の最小化問題として解釈できる．この汎函数はタスクそのものに対応する真の関数によって最小値をとるものであり，真のタスクとモデルが表現する関数の距離指標として解釈することが可能である．訓練過程ではこの関数を最小化することで，モデルに目標とするタスクを近似させることを試みる．    

さて，上記の定式化は以下の二つに強力な仮定を置いた：
- 訓練データとして入力空間全域の情報が漏れなく獲得できること
- 深層学習モデルが任意の関数を近似可能なこと

しかし，実際は訓練データは有限であるし，モデルの関数表現能力にも限界がある．これらの制約を踏まえると，深層学習モデルの訓練過程は以下のように定式化される．
$$
    \hat{f^*} = \argmin_{f_{\theta} \in \mathcal{F}}\hat{\mathcal{L}}(f)= \argmin_{f_{\theta} \in \mathcal{F}}\mathbb{E}_{x\in {\mathcal{D}}}[Loss(f_{\theta}(x),y)]
$$
ここで，$\mathcal{F}$はモデルアーキテクチャで表現可能な関数空間，$\mathcal{D}$は入力空間のうち，訓練データとして獲得されたサンプル集合である．
汎函数は獲得された有限の汎函数によって近似される．そのため，汎函数の最小値が目標とするタスクに対応する関数によって最小値が与えられるとは限らない点に注意が必要である．  
また，汎函数の最小値探索においてモデルの表現力によって，探索可能な領域に制約を受ける．  
そのため訓練過程は，有限の訓練データによって理想的な汎函数を近似し，モデルが表現可能な関数群を定義域として汎函数を最小化する関数を探索する問題として解釈することが可能となる．  

すなわち，訓練過程は近似された汎函数の最小化問題を，関数空間の部分空間を定義域として解く問題として解釈されるのである．

このように，訓練とは近似汎函数を制約付き関数空間内で最小化する過程である．この性質がどのようにして敵対的摂動の転移可能性の要因となりうるのかについて，次節で考察を行う．

### 
